# 从0开始学架构

## 基础架构

### 架构设计原则

- 简单原则
- 合适原则
- 演化原则

### 架构设计的复杂度来源

- 高性能
- 高可用
- 高扩展性
- other:低成本，安全，规模

### 架构设计流程

- 识别复杂度
- 设计备选方案

	- 常见的错误

		- 1.设计最优的方案，违背合适原则
		- 2.只做一个方案：容易陷入思考问题片面，自我坚持的认知陷阱。
		- 3.备选方案过于详细

	- 备选方案设计要点

		- 数量：3-5个
		- 备选方案差异要明显
		- 备选方案不要只局限于已经熟悉的技术
		- 关注技术选型，而不是技术细节

- 评估和选择备选方案

	- 选择方案的指导思想

		- 最简派
		- 最牛派
		- 最熟派
		- 领导派
		- 360度环评

		  列出我们需要关注的质量属性点，然后分别从这些质量属性的维度去评估每个方案，再综合挑选适合当时情况的最优方案。
		  数量对比：单纯数量可能会导致不重要的属性反而影响方案选择的关键因素。
		  加权法：无法客观的给予权重
		  优先级选择：即架构师综合当前的业务发展情况、团队人员规模和技能、业务发展预测等因素，将质量属性按照优先级排序，首先挑选满足第一优先级的，如果方案都满足，那就再看第二优先级……以此类推。
		  
- 详细方案设计

	- 避免备选方案被pass掉的前提

		- 架构师需要对备选方案的关键细节有比较深入的理解
		- 通过分步骤，分阶段，分系统等方式，降低实现方案的复杂度
		- 如果方案比较复杂，呢么就采取设计团队的方式，博采众长

- 实战：前浪微博

	- 需求：前浪微博的业务发展很快，系统也越来越多，因为各个系统之间耦合严重，所以系统间协作的效率很低。
	- 解决方向：使用消息队列系统来实现解耦
	- 复杂性分析

		- 高性能

			- 假设用户每天1000w条微博，每天1000w条消息，如果平均每一个消息有10个子系统读取，那么每天消息读取量为1亿。即平均：TPS=115，QPS=1150，峰值qps = 平均QPS * 3。那么TPS=345，QPS=3450。考虑业务发展，那么暂定为4倍。TPS 为 1380，QPS 为 13800

		- 高可用

			- 对于微博子系统来说，如果消息丢了，导致没有审核，然后触犯了国家法律法规，则是非常严重的事情；对于等级子系统来说，如果用户达到相应等级后，系统没有给他奖品和专属服务，则 VIP 用户会很不满意，导致用户流失从而损失收入，虽然也比较关键，但没有审核子系统丢消息那么严重。，所以需要高可用，包含消息写入，消息存储，消息读取都需要保证高可用性。

		- 高扩展

			- 只是一个消息系统，因此不需要考虑高扩展。

	- 设计备选方案

		- 1.开源kafka
		- 2.集群+MySql存储
		- 3.集群+自研存储方案

	- 评估和备选

		- 360环评

	- 详细设计方案

		- 数据库表如何设计

		  数据库设计两类表，一类是日志表，用于消息写入时快速存储到 MySQL 中；另一类是消息表，每个消息队列一张表。
		  业务系统发布消息时，首先写入到日志表，日志表写入成功就代表消息写入成功；后台线程再从日志表中读取消息写入记录，将消息内容写入到消息表中。
		  业务系统读取消息时，从消息表中读取。
		  日志表表名为 MQ_LOG，包含的字段：日志 ID、发布者信息、发布时间、队列名称、消息内容。
		  消息表表名就是队列名称，包含的字段：消息 ID（递增生成）、消息内容、消息发布时间、消息发布者。
		  日志表需要及时清除已经写入消息表的日志数据，消息表最多保存 30 天的消息数据。
		  
		- 数据如何复制

		  直接采用 MySQL 主从复制即可，只复制消息存储表，不复制日志表。
		  
		- 主备服务器如何倒换

		  采用 ZooKeeper 来做主备决策，主备服务器都连接到 ZooKeeper 建立自己的节点，主服务器的路径规则为“/MQ/server/ 分区编号 /master”，备机为“/MQ/server/ 分区编号 /slave”，节点类型为 EPHEMERAL。
		  
		  备机监听主机的节点消息，当发现主服务器节点断连后，备服务器修改自己的状态，对外提供消息读取服务。
		  
		- 业务服务器如何写入/读取消息

		  消息队列系统设计两个角色：生产者和消费者，每个角色都有唯一的名称。消息队列系统提供 SDK 供各业务系统调用
		  写入消息：SDK 从配置中读取所有消息队列系统的服务器信息，SDK 采取轮询算法发起消息写入请求给主服务器。如果某个主服务器无响应或者返回错误，SDK 将发起请求发送到下一台服务器。
		  读取消息：消息队列系统提供 SDK 供各业务系统调用，SDK 从配置中读取所有消息队列系统的服务器信息，轮流向所有服务器发起消息读取请求。消息队列服务器需要记录每个消费者的消费状态，即当前消费者已经读取到了哪条消息，当收到消息读取请求时，返回下一条未被读取的消息给消费者。
		  
		- 业务服务器和消息队列服务器之间的通信协议如何设计

		  考虑到消息队列系统后续可能会对接多种不同编程语言编写的系统，为了提升兼容性，传输协议用 TCP，数据格式为 ProtocolBuffer。
		  
		- 发送端和消费端如何寻址

		  利用zookeeper做注册中心，把broker的地址注册到zk上，发送端和消费端只要配置注册中心的地址即可获取集群所以broker地址，当有broker下线时，发送端和消费端能及时更新broker地址。
		  
		- 发送端消息重试

		  当发送消息发生网络异常时（不包括超时异常），可以重新选择下一台broker来重试发送，重试策略可以自定义。
		  
		- 消费消息采用什么模型？pull or push

		  考虑push模式会更复杂，故放弃，采用pull模式，消费端主动去拉，为了达到与push模式相同的低延迟效果，可以采用长轮询的方式，消费端轮询拉取消息费，当有消费可消费时，返回消息，如果没有可消费的消息，挂起当前线程，直到超时或者有可消费的消息为止。
		  
		- 消息重复问题

		  消息中间件不解决消息重复的问题，有业务系统自己根据业务的唯一id去重。
		  
		- 支持多消息类型

			- 顺序消息

			  发送端在发生顺序消息时，只发送到相同broker的相同队列，消费端消费时，顺序消息只能由同一个消费端消息。
			  
			- 定义消息

			  发送端指定消息延时多长时间消费，broker端定时扫描定时消息，达到延时时间的消息加入到消费队列。
			  
			- 事务消息

			  二阶段提交：发送端分两步，先预发送消息，broker端只记录消息为预发送状态，再执行本地事务，然后再根据本地事务的成功或者失败发送确认消息（回滚还是提交），这步如果发生异常，broker启动定时任务，把未确认的消息发送给发送端回查事务状态（需要发送端提供回查接口）。
			  
## 高可用集群架构

### cap/acid/base

- 分布式节点数据读写：CAP理论

  对于一个分布式计算系统，不可能同时满足一致性(Consistence)，可用性(Availability)，分区容错性(Partition tolerance)三个设计约束。
  
  CAP关注的是对数据的读写操作，而不是分布式系统的所有功能。
  
	- 理论

		- 一致性

		  对于某个指定的客户端来说，读操作保证能返回最新的写操作结果。
		  
		  因为事务执行过程中，系统处于一个不一致的状态，不同的节点的数据，并不完全一致。
		  
		- 可用性

		  我们的请求，不能超时，不能出错，结果是合理的，就算达到了可用性。
		  
		- 分区容错

		  发生了分区现象，不管是什么原因，可能是丢包，可能是连接中断，还可能是拥塞，只要导致了网络分区，就通通算在里面
		  
	- 应用

	  虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，我们会发现必须选择 P（分区容忍）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。如果我们选择了 CA 而放弃了 P，那么当发生分区现象时，为了保证 C，系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A 冲突了，因为 A 要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。
	  
		- CP

		  为了保证一致性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 需要返回 Error，提示客户端 C“系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。
		  
		- AP

		  为了保证可用性，当发生分区现象后，N1 节点上的数据已经更新到 y，但由于 N1 和 N2 之间的复制通道中断，数据 y 无法同步到 N2，N2 节点上的数据还是 x。这时客户端 C 访问 N2 时，N2 将当前自己拥有的数据 x 返回给客户端 C 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。
		  尽管X不是正确的结果，但是是合理的结果，因此满足可用性。
		  
	- 问题：基于Paxos算法构建的分布式系统，属于CAP架构中的哪一种？

- CAP细节点

  我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。
  
	- CAP是忽略网络延迟的
	- 正常运行情况下，不存在CP/AP的选择，可以同时满足CA
	- 放弃不等于什么都不做，需要为分区恢复后做准备

- 数据库事务：ACID

	- Atomicity：原子性

	  一个事务中的所有操作，要么全部完成，要么全部不完成，不会在中间某个环节结束。事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样。
	  
	- Consistency：一致性

	  在事务开始之前和事务结束以后，数据库的完整性没有被破坏。
	  
	- Isolation：隔离性

	  数据库允许多个并发事务同时对数据进行读写和修改的能力。隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括
	  读未提交（Read uncommitted）
	  读提交（read committed）
	  可重复读（repeatable read）
	  串行化（Serializable）
	  
	- Durability：持久化

	  事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。
	  
- BASE

	- Basically Available：基本可用

	  分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
	  
	- Soft State：软状态

	  允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。
	  
	- Eventual Consistency：最终一致性

	  系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。
	  
### 排除架构可用性隐患：FMEA

### 双机高可用架构

存储高可用方案的本质都是通过将数据复制到多个存储设备，通过数据冗余的方式来实现高可用，复杂性主要体现在如何应对复制延迟和中断导致数据不一致的问题。
数据如何复制？
各个节点的职责是什么？
如何应对复制延迟？
如何应对复制中断？

- 主备

  其整体架构比较简单，主备架构中的“备机”主要还是起到一个备份作用，并不承担实际的业务读写操作，如果要把备机改为主机，需要人工操作。
  
	- 优点

		- 对于客户端来说，不需要感知备机的存在
		- 对于主机和备机来说，双方只需要进行数据复制即可，无须进行状态判断和主备切换这类复杂的操作。

	- 缺点

		- 备机仅仅只为备份，并没有提供读写操作，硬件成本上有浪费。
		- 故障后需要人工干预，无法自动恢复。

	- 场景：管理系统等数据变更频率比较低的系统。

- 主从

  也就是说，主机负责读写操作，从机只负责读操作，不负责写操作。
  
	- 优点

		- 主从复制在主机故障时，读操作相关的业务可以继续运行。
		- 主从复制架构的从机提供读操作，发挥了硬件的性能。

	- 缺点

		- 主从复制架构中，客户端需要感知主从关系，并将不同的操作发给不同的机器进行处理，复杂度比主备复制要高。
		- 主从复制架构中，从机提供读业务，如果主从复制延迟比较大，业务会因为数据不一致出现问题。
		- 故障时需要人工干预。

	- 场景：适用于读多写少的场景。

- 主备/主从切换

	- 双机切换

		- 解决的问题：

			- 主备/主从如果主机故障后，无法进行写操作
			- 如果主机无法恢复，需要人工指定新的主机角色

		- 设计点

			- 主备间状态判断
			- 切换决策
			- 数据冲突解决

		- 常见架构

			- 互连式

			  互连式就是指主备机直接建立状态传递的渠道
			  
			- 中介式

			  中介式指的是在主备两者之外引入第三方中介，主备机之间不直接连接，而都去连接中介，并且通过中介来传递状态信息
			  
				- 问题：中介如何实现高可用
				- 开源实现的中介：Zookeeper,keepalived

			- 模拟式

			  模拟式指主备机之间并不传递任何状态数据，而是备机模拟成一个客户端，向主机发起模拟的读写操作，根据读写操作的响应情况来判断主机的状态。
			  
- 主主

  主主复制指的是两台机器都是主机，互相将数据复制给对方，客户端可以任意挑选其中一台机器进行读写操作.
  
  两台都是主机，不存在切换的概念。
  客户端无须区分不同角色的主机，随便将读写操作发送给哪台主机都可以。
  
### 数据集群和分区

- 数据集群：基于硬件故障考虑

	- 数据集中集群

	  数据集中集群与主备、主从这类架构相似，我们也可以称数据集中集群为 1 主多备或者 1 主多从。数据都只能往主机中写，而读操作可以参考主备、主从架构进行灵活多变。
	  
		- 复杂性

			- 主机如何将数据复制给备机
			- 备机如何检测主机状态
			- 主机故障后，如何决定新的主机

	- 数据分散集群

	  数据分散集群指多个服务器组成一个集群，每台服务器都会负责存储一部分数据；同时，为了提升硬件利用率，每台服务器又会备份一部分数据。类似与hadoop
	  
		- 复杂性

			- 均衡性

			  算法需要保证服务器上的数据分区基本是均衡的，不能存在某台服务器上的分区数量是另外一台服务器的几倍的情况。
			  
			- 容错性

			  当出现部分服务器故障时，算法需要将原来分配给故障服务器的数据分区分配给其他服务器。
			  
			- 可伸缩性

			  当集群容量不够，扩充新的服务器后，算法能够自动将部分数据分区迁移到新服务器，并保证扩容后所有服务器的均衡性。
			  
- 数据分区：基于地理级别故障

  数据分区指将数据按照一定的规则进行分区，不同分区分布在不同的地理位置上，每个分区存储一部分数据，通过这种方式来规避地理级别的故障所造成的巨大影响。采用了数据分区的架构后，即使某个地区发生严重的自然灾害或者事故，受影响的也只是一部分数据，而不是全部数据都不可用；当故障恢复后，其他地区备份的数据也可以帮助故障地区快速恢复业务。
  
	- 数据量
	- 分区规则

		- 备份：洲际分区/国家分区
		- 异地多活：城市分区

	- 复制规则

		- 集中式

		  集中式备份指存在一个总的备份中心，所有的分区都将数据备份到备份中心。
		  
		  
		  集中式备份架构的优缺点是：
		  优点：
		  设计简单，各分区之间并无直接联系，可以做到互不影响。
		  扩展容易，如果要增加第四个分区（例如，武汉分区），只需要将武汉分区的数据复制到西安备份中心即可，其他分区不受影响。
		  缺点：
		  成本较高，需要建设一个独立的备份中心。
		  
		- 互备式

		  互备式备份指每个分区备份另外一个分区的数据。
		  
		  优点：
		  成本低，直接利用已有的设备。
		  缺点：
		  设计比较复杂，各个分区除了要承担业务数据存储，还需要承担备份功能，相互之间互相关联和影响。
		  扩展麻烦，如果增加一个武汉分区，则需要修改广州分区的复制指向武汉分区，然后将武汉分区的复制指向北京分区。而原有北京分区已经备份了的广州分区的数据怎么处理也是个难题，不管是做数据迁移，还是广州分区历史数据保留在北京分区，新数据备份到武汉分区，无论哪种方式都很麻烦。
		  
		  
		  
		- 独立式

		  独立式备份指每个分区自己有独立的备份中心。
		  
		  设计简单，各分区互不影响。
		  扩展容易，新增加的分区只需要搭建自己的备份中心即可。
		  成本高，每个分区需要独立的备份中心，备份中心的场地成本是主要成本，因此独立式比集中式成本要高很多。
		  
### 计算高可用架构

因此计算高可用的本质是通过冗余来规避部分故障的风险，单台服务器是无论如何都达不到这个目标的。所以计算高可用的设计思想很简单：通过增加更多服务器来达到计算高可用。

设计复杂度主要体现在任务管理方面。

- 复杂点

	- 哪些服务器可以执行任务

		- 1.每个服务器都可以执行任务
		- 2.只有特定服务器（通常叫“主机”）可以执行任务

	- 任务如何重新执行

		- 1.已经分配的任务即使执行失败也不做任何处理，系统只需要保证新的任务能够分配到其他非故障服务器上执行即可。
		- 2.设计一个任务管理器来管理需要执行的计算任务，服务器执行完任务后，需要向任务管理器反馈任务执行结果，任务管理器根据任务执行结果来决定是否需要将任务重新分配到另外的服务器上执行。

- 主备

  主备方案的设计：
  主机执行所有计算任务。例如，读写数据、执行操作等。
  当主机故障（例如，主机宕机）时，任务分配器不会自动将计算任务发送给备机，此时系统处于不可用状态。
  如果主机能够恢复（不管是人工恢复还是自动恢复），任务分配器继续将任务发送给主机。
  如果主机不能够恢复（例如，机器硬盘损坏，短时间内无法恢复），则需要人工操作，将备机升为主机，然后让任务分配器将任务发送给新的主机（即原来的备机）；同时，为了继续保持主备架构，需要人工增加新的机器作为备机。
  
	- 冷备

	  备机上的程序包和配置文件都准备好，但备机上的业务系统没有启动（注意：备机的服务器是启动的），主机故障后，需要人工手工将备机的业务系统启动，并将任务分配器的任务请求切换发送给备机
	  
	- 温备

	  备机上的业务系统已经启动，只是不对外提供服务，主机故障后，人工只需要将任务分配器的任务请求切换发送到备机即可。冷备可以节省一定的能源，但温备能够大大减少手工操作时间，因此一般情况下推荐用温备的方式。
	  
- 主从

  和存储高可用中的主从复制架构类似，计算高可用的主从架构中的从机也是要执行任务的。任务分配器需要将任务进行分类，确定哪些任务可以发送给主机执行，哪些任务可以发送给备机执行。
  
  正常情况下，主机执行部分计算任务（如图中的“计算任务 A”），备机执行部分计算任务（如图中的“计算任务 B”）。
  当主机故障（例如，主机宕机）时，任务分配器不会自动将原本发送给主机的任务发送给从机，而是继续发送给主机，不管这些任务执行是否成功。
  如果主机能够恢复（不管是人工恢复还是自动恢复），任务分配器继续按照原有的设计策略分配任务，即计算任务 A 发送给主机，计算任务 B 发送给从机。
  如果主机不能够恢复（例如，机器硬盘损坏，短时间内无法恢复），则需要人工操作，将原来的从机升级为主机（一般只是修改配置即可），增加新的机器作为从机，新的从机准备就绪后，任务分配器继续按照原有的设计策略分配任务。
  
	- 优点：主从架构的从机也执行任务，发挥了从机的硬件性能。
	- 缺点：主从架构需要将任务分类，任务分配器会复杂一些。

- 集群

  主备架构和主从架构通过冗余一台服务器来提升可用性，且需要人工来切换主备或者主从。这样的架构虽然简单，但存在一个主要的问题：人工操作效率低、容易出错、不能及时处理故障。因此在可用性要求更加严格的场景中，我们需要系统能够自动完成切换操作，这就是高可用集群方案。
  
	- 对称集群

	  负载均衡集群设计细节：
	  正常情况下，任务分配器采取某种策略（随机、轮询等）将计算任务分配给集群中的不同服务器。
	  当集群中的某台服务器故障后，任务分配器不再将任务分配给它，而是将任务分配给其他服务器执行。
	  当故障的服务器恢复后，任务分配器重新将任务分配给它执行。
	  设计点：
	  任务分配器需要选取分配策略。
	  任务分配器需要检测服务器状态。
	  
	- 非对称集群

	  非对称集群中不同服务器的角色是不同的，不同角色的服务器承担不同的职责。以 Master-Slave 为例，部分任务是 Master 服务器才能执行，部分任务是 Slave 服务器才能执行。
	  
	  
	  非对称集群架构详细设计：
	  集群会通过某种方式来区分不同服务器的角色。例如，通过 ZAB 算法选举，或者简单地取当前存活服务器中节点 ID 最小的服务器作为 Master 服务器。
	  任务分配器将不同任务发送给不同服务器。例如，图中的计算任务 A 发送给 Master 服务器，计算任务 B 发送给 Slave 服务器。
	  当指定类型的服务器故障时，需要重新分配角色。例如，Master 服务器故障后，需要将剩余的 Slave 服务器中的一个重新指定为 Master 服务器；如果是 Slave 服务器故障，则并不需要重新分配角色，只需要将故障服务器从集群剔除即可。
	  设计复杂度主要体现在两个方面：
	  任务分配策略更加复杂：需要将任务划分为不同类型并分配给不同角色的集群节点。
	  角色分配策略实现比较复杂：例如，可能需要使用 ZAB、Raft 这类复杂的算法来实现 Leader 的选举。
	  
### 业务高可用：异地多活架构

- 架构模式

	- 同城异区：应对机房级别的故障

	  应对数据一致性要求比较高的业务。
	  
	- 跨城异地：城市级别的故障

	  而对数据一致性要求不那么高，或者数据不怎么改变，或者即使数据丢失影响也不大的业务，跨城异地多活就能够派上用场了。
	  
	- 跨国异地

		- 为不同地区用户提供服务
		- 只读类业务做多活

- 设计技巧

  采用多种手段，保证绝大部分用户的核心业务异地多活！
  
	- 1.保证核心业务的异地多活
	- 2.保证核心数据最终一致性

	  尽量减少异地多活机房的距离，搭建高速网络。
	  尽量减少数据同步，只同步核心业务相关的数据。
	  保证最终一致性，不保证实时一致性。
	  
	- 3.采用多种手段同步数据

		- 消息队列
		- 二次读取方式
		- 存储系统同步方案
		- 回源读取方式
		- 重新生成数据方式

	- 4.只保证大部分用户的异地多活

- 设计步骤

	- 1.业务分级

	  按照一定的标准将业务进行分级，挑选出核心的业务，只为核心业务设计异地多活，降低方案整体复杂度和实现成本。
	  
		- 访问量大的业务
		- 核心业务
		- 产生大量收入的业务

	- 2.数据分类

		- 数据量
		- 唯一性
		- 实时性
		- 可丢失性
		- 可恢复性

	- 3.数据同步

		- 存储系统同步
		- 消息队列同步
		- 重复生成

	- 4.异常处理

		- 多通道同步
		- 同步和访问结合
		- 日志记录

		  日志记录主要用于用户故障恢复后对数据进行恢复，其主要方式是每个关键操作前后都记录相关一条日志，然后将日志保存在一个独立的地方，当故障恢复后，拿出日志跟数据进行对比，对数据进行修复。
		  
		- 用户补偿

- 接口级故障

  解决接口级故障的核心思想和异地多活基本类似，都是优先保证核心业务和优先保证绝大部分用户。常见的应对方法有四种，降级、熔断、限流和排队，
  
	- 降级

	  降级指系统将某些业务或者接口的功能降低，可以是只提供部分功能，也可以是完全停掉所有功能。
	  
	  
	  降级的核心思想就是丢车保帅，优先保证核心业务。
	  
		- 系统后门降级
		- 独立降级系统

	- 熔断

	  熔断是指按照规则停掉外部接口的访问，防止某些外部接口故障导致自己的系统处理能力急剧下降或者出故障。
	  
		- 统一的 API 调用层
		- 阈值的设计

	- 限流

	  降级是从系统功能优先级的角度考虑如何应对故障，而限流则是从用户访问压力的角度来考虑如何应对故障。限流指只允许系统能够承受的访问量进来，超出系统访问能力的请求将被丢弃。
	  
		- 限流方式

			- 基于请求限流

				- 限制总量：限制某个指标的累积上限
				- 限制时间量：限制一段时间内某个指标的上限

			- 基于资源限流

			  而基于资源限流是从系统内部考虑的，也就是找到系统内部影响性能的关键资源，对其使用上限进行限制。常见的内部资源包括连接数、文件句柄、线程数和请求队列等。
			  
		- 限流算法

			- 时间窗

				- 固定时间窗
				- 滑动时间窗

			- 桶算法

			  用一个虚拟的“桶”来临时存储一些东西
			  
				- 漏桶

				  将请求放入“桶”（消息队列等），业务处理单元（线程、进程和应用等）从桶里拿请求处理，桶满则丢弃新的请求。
				  实现关键点：
				  流入速率不固定：可能瞬间流入非常多的请求，例如 0 点签到、整点秒杀。
				  匀速 (极速) 流出：这是理解漏桶算法的关键，也就是说即使大量请求进入了漏桶，但是从漏桶流出的速度是匀速的，速度的最大值就是系统的极限处理速度（对应图中的“极速”）。这样就保证了系统在收到海量请求的时候不被压垮，这是第一层的保护措施。需要注意的是：如果漏桶没有堆积，那么流出速度就等于流入速度，这个时候流出速度就不是匀速的。
				  桶满则丢弃请求：这是第二层保护措施，也就是说漏桶不是无限容量，而是有限容量，例如漏桶最多存储 100 万个请求，桶满了则直接丢弃后面的请求。
				  
				  主要适用于瞬时高并发流量的场景。
				  
				- 令牌桶

				  桶中放入的不是请求，而是“令牌”，这个令牌就是业务处理前需要拿到的“许可证”。也就是说，当系统收到一个请求时，先要到令牌桶里面拿“令牌”，拿到令牌才能进一步处理，拿不到就要丢弃请求。
				  
				  设计关键点：
				  有一个处理单元往桶里面放令牌，放的速率是可以控制的。
				  桶里面可以累积一定数量的令牌，当突发流量过来的时候，因为桶里面有累积的令牌，此时的业务处理速度会超过令牌放入的速度。
				  如果令牌不足，即使系统有能力处理，也会丢弃请求。
				  令牌桶算法的技术本质是速率控制。
				  要适用于两种典型的场景：
				  需要控制访问第三方服务的速度，防止把下游压垮，例如支付宝需要控制访问银行接口的速率
				  需要控制自己的处理速度，防止过载，例如压测结果显示系统最大处理 TPS 是 100，那么就可以用令牌桶来限制最大的处理速度。
				  
	- 排队

	  排队是让用户等待一段时间，全世界最有名的排队当属 12306 网站排队了。
	  
		- 1号店的双十一秒杀排队系统设计理念

## 可扩展架构

### 可扩展的基本思想：拆

拆，就是将原本大一统的系统拆分成多个规模小的部分，扩展时只修改其中一部分即可，无须整个系统到处都改，通过这种方式来减少改动范围，降低改动风险。

不同的拆分方式，本质上决定了系统的扩展方式。

- 面向流程拆分：分层架构

  将整个业务流程拆分为几个阶段，每个阶段作为一部分。
  
	- 展示层

	  负责用户页面设计，不同业务有不同的页面。例如，登录页面、注册页面、信息管理页面、安全设置页面等。
	  
	- 业务层

	  负责具体业务逻辑的处理。例如，登录、注册、信息管理、修改密码等业务。
	  
	- 数据层

	  负责完成数据访问。例如，增删改查数据库中的数据、记录事件到日志文件等。
	  
	- 存储层

	  负责数据的存储。例如，关系型数据库 MySQL、缓存系统 Memcache 等。
	  
- 面向服务拆分：SOA,微服务

  将系统提供的服务拆分，每个服务作为一部分。将系统拆分为注册、登录、信息管理、安全设置等服务
  
- 面向功能拆分：微内核

  将系统提供的功能拆分，每个功能作为一部分。每个服务都可以拆分为更多细粒度的功能
  
### 分层架构

核心关注点：
需要保证各层之间的差异足够清晰，边界足够明显，让人看到架构图后就能看懂整个架构。
层结构的另外一个特点就是层层传递，也就是说一旦分层确定，整个业务流程是按照层进行依次传递的，不能在层之间进行跳跃。

- B/S, C/S

  划分的对象是整个业务系统，划分的维度是用户交互，即将和用户交互的部分独立为一层，支撑用户交互的后台作为另外一层
  
- MVC/MVP

  划分的对象是单个业务子系统，划分的维度是职责，将不同的职责划分到独立层，但各层的依赖关系比较灵活。
  
- 逻辑分层

  划分的对象可以是单个业务子系统，也可以是整个业务系统，划分的维度也是职责。虽然都是基于职责划分，但逻辑分层架构和 MVC 架构、MVP 架构的不同点在于，逻辑分层架构中的层是自顶向下依赖的。典型的有操作系统内核架构、TCP/IP 架构。
  
- 优点：强制将分层依赖限定为两两依赖，降低了整体系统复杂度。

### SOA：整合系统

SOA 的全称是 Service Oriented Architecture，中文翻译为“面向服务的架构”。

SOA 更多是在传统企业（例如，制造业、金融业等）落地和推广。



- 关键概念

	- 服务

	  所有业务功能都是一项服务，服务就意味着要对外提供开放的能力，当其他系统需要使用这项功能时，无须定制化开发。
	  
	- ESB

	  ESB 的全称是 Enterprise Service Bus，中文翻译为“企业服务总线”。从名字就可以看出，ESB 参考了计算机总线的概念。计算机中的总线将各个不同的设备连接在一起，ESB 将企业中各个不同的服务连接在一起。因为各个独立的服务是异构的，如果没有统一的标准，则各个异构系统对外提供的接口是各式各样的。SOA 使用 ESB 来屏蔽异构系统对外提供各种不同的接口方式，以此来达到服务间高效的互联互通。
	  
	- 松耦合

	  松耦合的目的是减少各个服务间的依赖和互相影响。因为采用 SOA 架构后，各个服务是相互独立运行的，甚至都不清楚某个服务到底有多少对其他服务的依赖。如果做不到松耦合，某个服务一升级，依赖它的其他服务全部故障，这样肯定是无法满足业务需求的。
	  
- 优缺点

	- 优点：传统 IT 系统重复建设和扩展效率低的问题
	- 缺点：需要是实现与各种系统间的协议，数据转换，透明路由等，复杂性比较高，一旦承载消息太多，那么ESB本身就会成为整个系统的性能瓶颈。

### 微服务：服务拆分

- 经典观点

	- 微服务是 SOA 的实现方式： 

	  这种观点认为 SOA 是一种架构理念，而微服务是 SOA 理念的一种具体实现方法。例如，“微服务就是使用 HTTP RESTful 协议来实现 ESB 的 SOA”“使用 SOA 来构建单个系统就是微服务”和“微服务就是更细粒度的 SOA”。
	  
	- 微服务是去掉 ESB 后的 SOA：

	  点认为传统 SOA 架构最广为人诟病的就是庞大、复杂、低效的 ESB，因此将 ESB 去掉，改为轻量级的 HTTP 实现，就是微服务。
	  
	- 微服务是一种和 SOA 相似但本质上不同的架构理念：

	  这种观点认为微服务和 SOA 只是有点类似，但本质上是不同的架构设计理念。相似点在于下图中交叉的地方，就是两者都关注“服务”，都是通过服务的拆分来解决可扩展性问题。本质上不同的地方在于几个核心理念的差异：是否有 ESB、服务的粒度、架构设计的目标等。
	  
- 微服务(small,automated,lightweight) VS SOA
- 微服务的陷阱

	- 服务划分过细，服务间关系复杂： 

	  n 个服务的复杂度是 n×(n-1)/2，整体系统的复杂度是随着微服务数量的增加呈指数级增加的
	  
	- 服务数量太多，团队效率急剧下降

	  很多团队看到“微”字后，就想到必须将服务拆分得很细，有的团队人员规模是 5 ~ 6 个人，然而却拆分出 30 多个微服务，平均每个人要维护 5 个以上的微服务。
	  
	- 调用链太长，性能下降

	  由于微服务之间都是通过 HTTP 或者 RPC 调用的，每次调用必须经过网络。一般线上的业务接口之间的调用，平均响应时间大约为 50 毫秒，如果用户的一起请求需要经过 6 次微服务调用，则性能消耗就是 300 毫秒，这在很多高性能业务场景下是难以满足需求的。为了支撑业务请求，可能需要大幅增加硬件，这就导致了硬件成本的大幅上升。
	  
	- 调用链太长，问题定位困难

	  系统拆分为微服务后，一次用户请求需要多个微服务协同处理，任意微服务的故障都将导致整个业务失败。然而由于微服务数量较多，且故障存在扩散现象，快速定位到底是哪个微服务故障是一件复杂的事情。下面是一个典型样例。
	  
	- 没有自动化支撑，无法快速交付

	  如果没有相应的自动化系统进行支撑，都是靠人工去操作，那么微服务不但达不到快速交付的目的，甚至还不如一个大而全的系统效率高。例如：
	  
	- 没有服务治理，微服务数量多了后管理混乱

	  服务路由：假设某个微服务有 60 个节点，部署在 20 台机器上，那么其他依赖的微服务如何知道这个部署情况呢？
	  服务故障隔离：假设上述例子中的 60 个节点有 5 个节点发生故障了，依赖的微服务如何处理这种情况呢？
	  服务注册和发现：同样是上述的例子，现在我们决定从 60 个节点扩容到 80 个节点，或者将 60 个节点缩减为 40 个节点，新增或者减少的节点如何让依赖的服务知道呢？
	  
- 微服务方法篇

	- 服务粒度

	  针对微服务拆分过细导致的问题，我建议基于团队规模进行拆分，类似贝索斯在定义团队规模时提出的“两个披萨”理论（每个团队的人数不能多到两张披萨都不够吃的地步），分享一个我认为微服务拆分粒度的“三个火枪手”原则，即一个微服务三个人负责开发。
	  
	- 拆分方法

		- 基于业务逻辑拆分

		  这是最常见的一种拆分方式，将系统中的业务模块按照职责范围识别出来，每个单独的业务模块拆分为一个独立的服务。
		  
		  拆分数量根据三个火枪手理论指定数量：例如100个人的开发团队，服务划分为40个。10人团队，服务的数量为4个。
		  
		- 基于可扩展拆分

		  将系统中的业务模块按照稳定性排序，将已经成熟和改动不大的服务拆分为稳定服务，将经常变化和迭代的服务拆分为变动服务。稳定的服务粒度可以粗一些，即使逻辑上没有强关联的服务，也可以放在同一个子系统中，例如将“日志服务”和“升级服务”放在同一个子系统中；不稳定的服务粒度可以细一些，但也不要太细，始终记住要控制服务的总数量。
		  
		  主要是为了提升项目快速迭代的效率，避免在开发的时候，不小心影响了已有的成熟功能导致线上问题。
		  
		- 基于可靠性拆分

		  将系统中的业务模块按照优先级排序，将可靠性要求高的核心服务和可靠性要求低的非核心服务拆分开来，然后重点保证核心服务的高可用。具体拆分的时候，核心服务可以是一个也可以是多个，只要最终的服务数量满足“三个火枪手”的原则就可以。
		  
		  好处：
		  避免非核心服务故障影响核心服务
		  核心服务高可用方案可以更简单
		  能够降低高可用成本
		  
		- 基于性能拆分

		  基于性能拆分和基于可靠性拆分类似，将性能要求高或者性能压力大的模块拆分出来，避免性能压力大的服务影响其他服务。
		  
		  常见的拆分方式和具体的性能瓶颈有关，可以拆分 Web 服务、数据库、缓存等。例如电商的抢购，性能压力最大的是入口的排队功能，可以将排队功能独立为一个服务。
		  
	- 基础设施

		- 1.服务发现、服务路由、服务容错：这是最基本的微服务基础设施。

		  服务发现：微服务种类和数量很多，如果手工配置，那么工作量太庞大。实现方式有一下两种：
		  自理式：自理式服务发现实现比较简单，因为这部分的功能一般通过统一的程序库或者程序包提供给各个微服务调用，而不会每个微服务都自己来重复实现一遍；并且由于每个微服务都承担了服务发现的功能，访问压力分散到了各个微服务节点，性能和可用性上不存在明显的压力和风险。
		  代理式：代理式结构就是指微服务之间有一个负载均衡系统（图中的 LOAD BALANCER 节点），由负载均衡系统来完成微服务之间的服务发现。
		  不管是自理式还是代理式，服务发现的核心功能就是服务注册表，注册表记录了所有的服务节点的配置和状态，每个微服务启动后都需要将自己的信息注册到服务注册表，然后由微服务或者 LOAD BALANCER 系统到服务注册表查询可用服务。服务路由。
		  
		  服务路由：有了服务发现后，微服务之间能够方便地获取相关配置信息，但具体进行某次调用请求时，我们还需要从所有符合条件的可用微服务节点中挑选出一个具体的节点发起请求，这就是服务路由需要完成的功能。
		  
		  服务容错：系统拆分为微服务后，单个微服务故障的概率变小，故障影响范围也减少，但是微服务的节点数量大大增加。从整体上来看，系统中某个微服务出故障的概率会大大增加。
		  微服务陷阱时提到微服务具有故障扩散的特点，如果不及时处理故障，故障扩散开来就会导致看起来系统中很多服务节点都故障了，因此需要微服务能够自动应对这种出错场景，及时进行处理，所以我们需要服务容错的能力。
		  
		  请求重试、流控和服务隔离
		  
		  
		  
		  
		- 2.接口框架、API 网关：主要是为了提升开发效率，接口框架是提升内部服务的开发效率，API 网关是为了提升与外部服务对接的效率。

		  接口框架：微服务提倡轻量级的通信方式，一般采用 HTTP/REST 或者 RPC 方式统一接口协议。
		  
		  API网关：系统拆分为微服务后，内部的微服务之间是互联互通的，相互之间的访问都是点对点的。外部系统只会关注它需要的能力，而不会关注这个能力应该由哪个微服务提供。微服务需要一个统一的 API 网关，负责外部系统的访问操作。主要包括接入鉴权（是否允许接入）、权限控制（可以访问哪些功能）、传输加密、请求路由、流量控制等功能。
		  
		- 3.自动化部署、自动化测试、配置中心：主要是为了提升测试和运维效率。

		  自动化测试：快速交付，快速迭代的保证。
		  
		  自动化部署：相对于大一统的系统，微服务需要部署的节点增加了几倍甚至几十倍，部署频率也大幅上升，因此如果手工处理，需要投入大量的人力，而且容易出错。
		  
		  配置中心：微服务的节点数量非常多，通过人工登录每台机器手工修改，效率低，容易出错。
		  
		  
		  
		- 4.服务监控、服务跟踪、服务安全：主要是为了进一步提升运维效率。

		  服务监控：系统拆分为微服务后，节点数量大大增加，导致需要监控的机器、网络、进程、接口调用数等监控对象的数量大大增加，需要服务监控系统来完成微服务节点的监控。
		  作用：
		  实时搜集信息并进行分析，避免故障后再来分析，减少了处理时间。
		  服务监控可以在实时分析的基础上进行预警，在问题萌芽的阶段发觉并预警，降低了问题影响的范围和时间。
		  服务跟踪：
		  服务监控和服务跟踪的区别可以简单概括为宏观和微观的区别。例如，A 服务通过 HTTP 协议请求 B 服务 10 次，B 通过 HTTP 返回 JSON 对象，服务监控会记录请求次数、响应时间平均值、响应时间最高值、错误码分布这些信息；而服务跟踪会记录其中某次请求的发起时间、响应时间、响应错误码、请求参数、返回的 JSON 对象等信息。
		  Google 的 Dapper 论文
		  
		  服务安全：
		  系统拆分为微服务后，数据分散在各个微服务节点上。从系统连接的角度来说，任意微服务都可以访问所有其他微服务节点；但从业务的角度来说，部分敏感数据或者操作，只能部分微服务可以访问，而不是所有的微服务都可以访问，因此需要设计服务安全机制来保证业务和数据的安全性。
		  服务安全主要分为三部分：接入安全、数据安全、传输安全。通常情况下，服务安全可以集成到配置中心系统中进行实现，即配置中心配置微服务的接入安全策略和数据安全策略，微服务节点从配置中心获取这些配置信息，然后在处理具体的微服务调用请求时根据安全策略进行处理。由于这些策略是通用的，一般会把策略封装成通用的库提供给各个微服务调用。基本架构如下：
		  ￼
		  
		  
	- 微内核架构

	  微内核架构（Microkernel Architecture），也被称为插件化架构（Plug-in Architecture），是一种面向功能进行拆分的可扩展性架构，通常用于实现基于产品（原文为 product-based，指存在多个版本、需要下载安装才能使用，与 web-based 相对应）的应用。
	  
		- 设计关键点

			- 插件管理
			- 插件连接
			- 插件通信

		- OSGi 架构

		  OSGi 的全称是 Open Services Gateway initiative。OSGi 联盟的初始目标是构建一个在广域网和局域网或设备上展开业务的基础平台，所以 OSGi 的最早设计也是针对嵌入式应用的，诸如机顶盒、服务网关、手机、汽车等都是其应用的主要环境。然而，无心插柳柳成荫，由于 OSGi 具备动态化、热插拔、高可复用性、高效性、扩展方便等优点，它被应用到了 PC 上的应用开发。现在我们谈论 OSGi，已经和嵌入式应用关联不大了，更多是将 OSGi 当作一个微内核的架构模式。
		  
			- Module 层

			  模块层实现插件管理功能。OSGi 中，插件被称为 Bundle，每个 Bundle 是一个 Java 的 JAR 文件，每个 Bundle 里面都包含一个元数据文件 MANIFEST.MF，这个文件包含了 Bundle 的基本信息。例如，Bundle 的名称、描述、开发商、classpath，以及需要导入的包和输出的包等，OSGi 核心系统会将这些信息加载到系统中用于后续使用。
			  
			- Lifecycle 层

			  生命周期层实现插件连接功能，提供了执行时模块管理、模块对底层 OSGi 框架的访问。生命周期层精确地定义了 Bundle 生命周期的操作（安装、更新、启动、停止、卸载），Bundle 必须按照规范实现各个操作。
			  
			- service层

			  服务层实现插件通信的功能。OSGi 提供了一个服务注册的功能，用于各个插件将自己能提供的服务注册到 OSGi 核心的服务注册中心，如果某个服务想用其他服务，则直接在服务注册中心搜索可用服务中心就可以了。
			  
		- 规则引擎

		  规则引擎从结构上来看也属于微内核架构的一种具体实现，其中执行引擎可以看作是微内核，执行引擎解析配置好的业务流，执行其中的条件和规则，通过这种方式来支持业务的灵活多变。
		  
			- 优点

				- 可扩展

				  通过引入规则引擎，业务逻辑实现与业务系统分离，可以在不改动业务系统的情况下扩展新的业务功能。
				  
				- 易理解

				  规则通过自然语言描述，业务人员易于理解和操作，而不像代码那样只有程序员才能理解和开发。
				  
				- 高效率

				  规则引擎系统一般提供可视化的规则定制、审批、查询及管理，方便业务人员快速配置新的业务。
				  
			- 实现机制

				- 插件管理

				  规则引擎中的规则就是微内核架构的插件，引擎就是微内核架构的内核。规则可以被引擎加载和执行。规则引擎架构中，规则一般保存在规则库中，通常使用数据库来存储。
				  
				- 插件连接

				  类似于程序员开发的时候需要采用 Java、C++ 等语言，规则引擎也规定了规则开发的语言，业务人员需要基于规则语言来编写规则文件，然后由规则引擎加载执行规则文件来完成业务功能，因此，规则引擎的插件连接实现机制其实就是规则语言。
				  
				- 插件通信

				  规则引擎的规则之间进行通信的方式就是数据流和事件流，由于单个规则并不需要依赖其他规则，因此规则之间没有主动的通信，规则只需要输出数据或者事件，由引擎将数据或者事件传递到下一个规则。
				  
			- 实现产品：Drools

## 高性能架构模式

### 高性能数据库集群

- 数据库读写分离

  使用读写分离将访问压力分散到集群中的多个节点，但是没有分散存储压力。
  ￼
  主从集群基本实现：
  数据库服务器搭建主从集群，一主一从，一主多从。
  数据库主机负责读写操作，从机只负责读操作。
  数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。
  业务服务器将写操作发给数据库主机，将读操作发给数据库从机
  
  
	- 主从延迟

	  主从复制延迟：
	  写操作后的读操作发送给指定数据库主服务器。
	  读从机失败后再读一次主机。
	  关键业务读写操作全部指向主机，非关键业务采用读写分离。
	  
	- 分配机制

	  分配机制：
	  程序代码封装：代码中抽象一个数据访问层，实现读写操作分离和数据库服务器连接的管理，比如使用hibernate。￼开源实现方案中，淘宝的TDDL是比较有名的，基于集中式配置的jdbc datasource实现，具备主备，读写分离，动态数据库配置等功能，基本架构是：
	  ￼2.中间件封装
	  中间件封装指的是独立一套系统出来，实现读写操作分离和数据库服务器连接的管理。中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。其基本架构是：
	  ￼
	  
	  知名开源数据库中间件方案：
	  MYSQL proxy：一直没有GA
	  Mysql Router：官方推荐，有读写分离、故障自动切换、负载均衡、连接池等
	  奇虎360的Atlas：基于Mysql Proxy实现
	  
	  
- 数据库分库分表

	- 解决的问题

	  读写分离分散了数据库读写操作的压力，但没有分散存储压力，当数据量达到千万甚至上亿条的时候，单台数据库服务器的存储能力会成为系统的瓶颈，主要体现在这几个方面：
	  数据量太大，读写的性能会下降，即使有索引，索引也会变得很大，性能同样会下降。
	  数据文件会变得很大，数据库备份和恢复需要耗费很长时间。
	  数据文件越大，极端情况下丢失数据的风险越高（例如，机房火灾导致数据库主备机都发生故障）。
	  
	- 业务分库

	  业务分库指的是按照业务模块将数据分散到不同的数据库服务器。
	  ￼
	  
		- Join操作问题

		  无法执行Join查询
		  
		- 事务问题

		  原本在同一个数据库中不同的表可以在同一个事务中修改，业务分库之后，表分散在不同的数据库中，无法通过事务统一修改。分布式事务如XA，性能又比较低，和高性能存储的目标是相违背的。
		  
		- 成本问题

		  小公司，可以从单机开始，单台服务器也可以支撑10w用户量量级的业务。
		  业务成熟的大公司，已经有了业务分库的成熟解决方案，即便尝试新业务，用户规模也是海量的。
		  
	- 分表

		- 垂直分表

		  垂直切分之后，两个表的数量是一样的，但是包含的列被拆分开来。
		  
			- 问题1：多次查询才可以达到之前一次查询的效果

		- 水平切分

		  列相同，将表中数据拆分成两个表。
		  
		  当表的数据量达到千万级别的时候，作为架构师就要警觉起来了，因为这很可能是架构的性能瓶颈或者隐患。
		  
			- 问题1：路由

			  水平分表之后，某条数据具体属于那个切分后的子表，需要增加路由算法进行计算，这个算法会引入一定的复杂性。
			  范围路由：选取有序的数据列作为路由的条件，不同分段分散到不同的数据库表中。分段大小推荐在100w--2000w。比较隐含的缺点是分布不均匀。
			  Hash路由：选取某些列的值进行Hash运算，让那后根据Hash结果分散到不同的数据库表中。优点是分布均匀。缺点是增加子表数量的时候比较麻烦，
			  配置路由：配置单独的路由表，以用户ID为例，新增一张user_router表，这个表包含user_id和table_id，根据user_id可以查询对应table_id。缺点是必须多查询一次，如果路由表达到亿级别，那么性能又会称为瓶颈。
			  
			  
			  
			- 问题2：Join操作

			  需要多次join然后进行汇总
			  
			- 问题3：count操作

			  1.多次count，然后数量相加。
			  2.记录数表，每次add/delete，都修改记录数表，因为事务问题，可能会出现数据不一致的情况，对于数据不一定要求精确的业务，可以通过后台定时更新记录数表。
			  
			- 问题4：order by操作

			  水平分表后，数据分散到多个子表中，排序操作无法在数据库中完成，只能由业务代码或者数据库中间件分别查询每个子表中的数据，然后汇总进行排序。
			  
### 高性能Nosql

- 为什么需要NoSql

  关系数据库存储的是行记录，无法存储数据结构。
  关系数据库的 schema 扩展很不方便
  关系数据库在大数据场景下 I/O 较高。
  关系数据库的全文搜索功能比较弱：只能使用like进行整表扫描匹配，性能非常低，在互联网这种搜索复杂的场景下无法满足业务要求。
  
- 常见的NoSql存储方案

	- K-V存储：reids
	- 文档数据库：MongoDb
	- 列式存储：HBase
	- 全文搜索引擎：Elasticsearch

### 高性能缓存架构

缓存就是为了弥补存储系统在这些复杂业务场景下的不足，其基本原理是将可能重复使用的数据放到内存中，一次生成、多次使用，避免每次使用都去访问存储系统。

- 缓存穿透

  缓存穿透是指缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，业务系统需要再次去存储系统查询数据。
  
	- 存储数据不存在

	  果查询存储系统的数据没有找到，则直接设置一个默认值（可以是空值，也可以是具体的值）存到缓存中，这样第二次读取缓存时就会获取到默认值，而不会继续访问存储系统。
	  
	- 缓存数据生成耗费大量时间或者资源

	  第二种情况是存储系统中存在数据，但生成缓存数据需要耗费较长时间或者耗费大量资源。如果刚好在业务访问的时候缓存失效了，那么也会出现缓存没有发挥作用，访问压力全部集中在存储系统上的情况。
	  
	  由于难以预测用户到底会访问哪些分页，因此业务上最简单的就是每次点击分页的时候按分页计算和生成缓存。
	  
- 缓存雪崩

  缓存雪崩是指当缓存失效（过期）后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算，这个处理步骤耗时几十毫秒甚至上百毫秒。对于高并发的业务系统来说，可能在这个时间内接到上千个请求，由于新的缓存已经被清除，新的缓存还未生成，并且处理这些请求的线程都不知道另外有一个线程正在生成缓存，因此所有的请求都会去重新生成缓存，都会去访问存储系统，从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。
  
	- 更新锁

	  对缓存更新操作进行加锁保护，保证只有一个线程能够进行缓存更新，未能获取更新锁的线程要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
	  
	  分布式集群业务系统需要使用到分布式锁。
	  
	- 后台更新

	  由后台线程来更新缓存，而不是由业务线程来更新缓存，缓存本身的有效期设置为永久，后台线程定时更新缓存。
	  
	  
	  后台更新既适应单机多线程的场景，也适合分布式集群的场景，相比更新锁机制要简单一些。后台更新机制还适合业务刚上线的时候进行缓存预热。缓存预热指系统上线后，将相关的缓存数据直接加载到缓存系统，而不是等待用户访问才来触发缓存加载。
	  
- 缓存热点

  对于一些特别热点的数据，如果大部分甚至所有的业务请求都命中同一份缓存数据，则这份数据所在的缓存服务器的压力也很大。
  
  
  缓存热点的解决方案就是复制多份缓存副本，将请求分散到多个缓存服务器上，减轻缓存热点导致的单台缓存服务器压力。
  
  
  以微博为例，对于粉丝数超过 100 万的明星，每条微博都可以生成 100 份缓存，缓存的数据是一样的，通过在缓存的 key 里面加上编号进行区分，每次读缓存时都随机读取其中某份缓存。
  
  不同的缓存副本不要设置统一的过期时间，否则就会出现所有缓存副本同时生成同时失效的情况，从而引发缓存雪崩效应。正确的做法是设定一个过期时间范围，不同的缓存副本的过期时间是指定范围内的随机值。
  
### 单服务器高性能模式

架构设计决定了系统性能的上限，实现细节决定了系统性能的下限。

单服务器高性能的关键之一就是服务器采取的并发模型，关键点如下：
服务器如何管理连接。
服务器如何处理请求。
以上两点都和操作系统的I/O模型及进程模型相关
I/O 模型：阻塞、非阻塞、同步、异步。
进程模型：单进程、多进程、多线程。


- PPC和TPC：常量连接

	- PPC：Process Per Connection

	  含义：是指每次有新的连接就新建一个进程去专门处理这个连接的请求，这是传统的 UNIX 网络服务器所采用的模型。
	  
	  过程：
	  父进程接受连接（图中 accept）。
	  父进程“fork”子进程（图中 fork）。
	  子进程处理连接的读写请求（图中子进程 read、业务处理、write）。
	  子进程关闭连接（图中子进程中的 close）。
	  注意：图中有一个小细节，父进程“fork”子进程后，直接调用了 close，看起来好像是关闭了连接，其实只是将连接的文件描述符引用计数减一，真正的关闭连接是等子进程也调用 close 后，连接对应的文件描述符引用计数变为 0 后，操作系统才会真正关闭连接。
	  
	  prefork：提前创建好一些进程。
	  
	  一般情况下，PPC 方案能处理的并发连接数量最大也就几百。
	  
	  例如：Apache的 MPM prefork
	  
		- 问题：fork进程代价高，且父子进程通信比较麻烦。

	- 并发模式如何选

	  别是响应时间（RT），并发数（Concurrency），吞吐量（TPS）。三者关系，吞吐量=并发数/平均响应时间。不同类型的系统，对这三个指标的要求不一样。
	  
		-  三高系统，比如秒杀、即时通信，不能使用。
		- 三低系统，比如ToB系统，运营类、管理类系统，一般可以使用。
		- 高吞吐系统，如果是内存计算为主的，一般可以使用，如果是网络IO为主的，一般不能使用。

	- TPC：Thread Per Connection

	  含义：指每次有新的连接就新建一个线程去专门处理这个连接的请求。与进程相比，线程更轻量级，创建线程的消耗比进程要少得多；同时多线程是共享进程内存空间的，线程通信相比进程通信更简单。
	  
	  过程：
	  父进程接受连接（图中 accept）。
	  父进程创建子线程（图中 pthread）。
	  子线程处理连接的读写请求（图中子线程 read、业务处理、write）。
	  子线程关闭连接（图中子线程中的 close）。
	  注意：和 PPC 相比，主进程不用“close”连接了。原因是在于子线程是共享主进程的进程空间的，连接的文件描述符并没有被复制，因此只需要一次 close 即可。
	  
	  问题：
	  创建线程虽然比创建进程代价低，但并不是没有代价，高并发时（例如每秒上万连接）还是有性能问题。
	  无须进程间通信，但是线程间的互斥和共享又引入了复杂度，可能一不小心就导致了死锁问题。
	  多线程会出现互相影响的情况，某个线程出现异常时，可能导致整个进程退出（例如内存越界）。
	  prethread：提前创建线程
	  
	  Apache的MPM worker。
	  
		- 问题：可能会出现死锁现象，稳定性没有PPC稳定

- Reactor和Proactor：海量连接

	- Reactor：非阻塞同步网络模型

	  I/O 多路复用统一监听事件，收到事件后分配（Dispatch）给某个进程。
	  
		- 解决的问题：PPC/TPC无法连接复用

		  I/O 多路复用结合线程池解决PPC/TPC的问题
		  
		  I/O 多路复用技术归纳起来有两个关键实现点：
		  当多条连接共用一个阻塞对象后，进程只需要在一个阻塞对象上等待，而无须再轮询所有连接，常见的实现方式有 select、epoll、kqueue 等。
		  当某条连接有新的数据可以处理时，操作系统会通知进程，进程从阻塞状态返回，开始进行业务处理。
		  
		- 组成

			- Reactor

			  Reactor 负责监听和分配事件
			  
			- 处理资源池(进程池/线程池)

			  处理资源池负责处理事件。
			  
		- 典型实现方案

			- 单 Reactor 单进程 / 线程。

			  单 Reactor 单进程的方案在实践中应用场景不多，只适用于业务处理非常快速的场景，目前比较著名的开源软件中使用单 Reactor 单进程的是 Redis。
			  
			  C 语言编写系统的一般使用单 Reactor 单进程
			  而 Java 语言编写的一般使用单 Reactor 单线程
			  
			  
			- 单 Reactor 多线程。

			  方案：
			  主线程中，Reactor 对象通过 select 监控连接事件，收到事件后通过 dispatch 进行分发。
			  如果是连接建立的事件，则由 Acceptor 处理，Acceptor 通过 accept 接受连接，并创建一个 Handler 来处理连接后续的各种事件。
			  如果不是连接建立事件，则 Reactor 会调用连接对应的 Handler（第 2 步中创建的 Handler）来进行响应。
			  Handler 只负责响应事件，不进行业务处理；Handler 通过 read 读取到数据后，会发给 Processor 进行业务处理。
			  Processor 会在独立的子线程中完成真正的业务处理，然后将响应结果发给主进程的 Handler 处理；Handler 收到响应后通过 send 将响应结果返回给 client。
			  
			- 多 Reactor 多进程 / 线程。

			  父进程中 mainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 接收，将新的连接分配给某个子进程。
			  子进程的 subReactor 将 mainReactor 分配的连接加入连接队列进行监听，并创建一个 Handler 用于处理连接的各种事件。
			  当有新的事件发生时，subReactor 会调用连接对应的 Handler（即第 2 步中创建的 Handler）来进行响应。
			  Handler 完成 read→业务处理→send 的完整业务流程。
			  多 Reactor 多进程 / 线程的方案看起来比单 Reactor 多线程要复杂，但实际实现时反而更加简单，主要原因是：
			  父进程和子进程的职责非常明确，父进程只负责接收新连接，子进程负责完成后续的业务处理。
			  父进程和子进程的交互很简单，父进程只需要把新连接传给子进程，子进程无须返回数据。
			  子进程之间是互相独立的，无须同步共享之类的处理（这里仅限于网络模型相关的 select、read、send 等无须同步共享，“业务处理”还是有可能需要同步共享的）。
			  实现：Nginx 采用的是多 Reactor 多进程，采用多 Reactor 多线程的实现有 Memcache 和 Netty。
			  
	- Proactor：非阻塞异步网络模型

### 高性能负载均衡

高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法。

- 负载均衡分类

	- DNS负载均衡

	  优点：
	  简单、成本低：负载均衡工作交给 DNS 服务器处理，无须自己开发或者维护负载均衡设备。
	  就近访问，提升访问速度：DNS 解析时可以根据请求来源 IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。
	  
	  缺点：
	  更新不及时：DNS 缓存的时间比较长，修改 DNS 配置后，由于缓存的原因，还是有很多用户会继续访问修改前的 IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。
	  扩展性差：DNS 负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。
	  分配策略比较简单：DNS 负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。
	  
	  可以一句Http协议自己实现http-dns功能
	  
	- 硬件负载均衡

	  优点：
	  功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。
	  性能强大：对比一下，软件负载均衡支持到 10 万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。
	  稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。
	  支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防 DDoS 攻击等安全功能。
	  缺点：
	  价格昂贵：最普通的一台 F5 就是一台“马 6”，好一点的就是“Q7”了。
	  扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制
	  
		- f5
		- a10

	- 软件负载均衡

		- nginx：七层网络协议

		  支持协议：支持Http, email。
		  性能：5w/s
		  
		- LVS：四层网络协议

		  
		  支持协议：而 LVS 是 4 层负载均衡，和协议无关，几乎所有应用都可以做，例如，聊天、数据库等。
		  性能：10w每秒
		  
- 组合原则

	- DNS 负载均衡用于实现地理级别的负载均衡
	- 硬件负载均衡用于实现集群级别的负载均衡
	- 软件负载均衡用于实现机器级别的负载均衡。

- 实战：日活千万的论坛

   日活千万的论坛，这个流量不低了。
  1、首先，流量评估。
         1000万DAU，换算成秒级，平均约等于116。
  	考虑每个用户操作次数，假定10，换算成平均QPS=1160。
         考虑峰值是均值倍数，假定10，换算成峰值QPS=11600。
         考虑静态资源、图片资源、服务拆分等，流量放大效应，假定10，QPS*10=116000。 
  
  2、其次，容量规划。
         考虑高可用、异地多活，QPS*2=232000。
         考虑未来半年增长，QPS*1.5=348000。
  3、最后，方案设计。
         三级导流。
         第一级，DNS，确定机房，以目前量级，可以不考虑。
         第二级，确定集群，扩展优先，则选Haproxy/LVS，稳定优先则选F5。
         第三级，Nginx+KeepAlived，确定实例。
  
### 算法

- 任务平分类

  负载均衡系统将收到的任务平均分配给服务器进行处理，这里的“平均”可以是绝对数量的平均，也可以是比例或者权重上的平均。
  
- 负载均衡类

  负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的“CPU 负载”，而是系统当前的压力，可以用 CPU 负载来衡量，也可以用连接数、I/O 使用率、网卡吞吐量等来衡量系统的压力
  
	- 轮询

	  负载均衡系统收到请求后，按照顺序轮流分配到服务器上。
	  
	- 加权轮询
	- 负载最低优先

- 性能最优类

  负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。
  
  
  负载最低优先类算法是站在服务器的角度来进行分配的，而性能最优优先类算法则是站在客户端的角度来进行分配的，优先将任务分配给处理速度最快的服务器，通过这种方式达到最快响应客户端的目的。
  
- hash类

  负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址 Hash、session id hash、用户 ID Hash 等。
  
  负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同 Hash 值的请求分配到同一台服务器上，这样做的目的主要是为了满足特定的业务需求。
  
	- 源地址 Hash
	- ID Hash

## 架构实战

### 架构师如何判断技术演进的方向？

- 派别划分

	- 潮流派
	- 保守派
	- 跟风派

- 技术演进的动力：企业业务的发展

	- 产品类：技术创新推动业务发展，选择的驱动力是功能。
	- 服务类：业务发展推动技术的发展，选择驱动力是规模。比如我们大家都使用微信。

### 互联网技术演进的模式

互联网业务千差万别，但由于它们具有“规模决定一切”的相同点，其发展路径也基本上是一致的。互联网业务发展一般分为几个时期：初创期、发展期、竞争期、成熟期。不同时期的差别主要体现在两个方面：复杂性、用户规模。

- 业务复杂性

  互联网业务发展第一个主要方向就是“业务越来越复杂”
  
	- 初创期：新

	  互联网业务刚开始一般都是一个创新的业务点，这个业务点的重点不在于“完善”，而在于“创新”，只有创新才能吸引用户；而且因为其“新”的特点，其实一开始是不可能很完善的。只有随着越来越多的用户的使用，通过快速迭代试错、用户的反馈等手段，不断地在实践中去完善，才能继续创新。
	  
	  初创期的业务对技术的第一个要求就是：快，所以能买就买，有开源的就用开源的。
	  
	- 发展期：快

	  业务快速发展时期的主要目的是将原来不完善的业务逐渐完善，因此会有越来越多的新功能不断地加入到系统中。对于绝大部分技术团队来说，这个阶段技术的核心工作是快速地实现各种需求，只有这样才能满足业务发展的需要。
	  
		- 堆功能期
		- 优化期

			- 优化派

			  优化派的核心思想是将现有的系统优化。例如，采用重构、分层、优化某个 MySQL 查询语句，将机械硬盘换成 SSD，将数据库从 MySQL 换成 Oracle，增加 Memcache 缓存等。优化派的优势是对系统改动较小，优化可以比较快速地实施；缺点就是可能过不了多久，系统又撑不住了。
			  
			- 架构派

			  架构派的核心思想是调整系统架构，主要是将原来的大系统拆分为多个互相配合的小系统。
			  
			  架构期可以用的手段很多，但归根结底可以总结为一个字“拆”，什么地方都可以拆。
			  拆功能：例如，将购物系统拆分为登录认证子系统、订单系统、查询系统、分析系统等。
			  拆数据库：MySQL 一台变两台，2 台变 4 台，增加 DBProxy、分库分表等。
			  拆服务器：服务器一台变两台，2 台变 4 台，增加负载均衡的系统，如 Nginx、HAProxy 等。
			  
	- 竞争期

	  当竞争对手加入后，大家互相学习和模仿，业务更加完善，也不断有新的业务创新出来，而且由于竞争的压力，对技术的要求是更上一层楼了。
	  
	  问题：
	  重复造轮子
	  系统交互一团乱麻
	  
		- 平台化：解决重复造轮子的问题
		- 服务化：解决系统交互的问题

	- 成熟期

	  当企业熬过竞争期，成为了行业的领头羊，或者整个行业整体上已经处于比较成熟的阶段，市场地位已经比较牢固后，业务创新的机会已经不大，竞争压力也没有那么激烈，此时求快求新已经没有很大空间，业务上开始转向为“求精”：我们的响应时间是否比竞争对手快？我们的用户体验是否比竞争对手好？我们的成本是否比竞争对手低
	  
- 用户规模

  用户量增大对技术的影响主要体现在两个方面：性能要求越来越高、可用性要求越来越高。
  
	- 性能

	  用户量增大给技术带来的第一个挑战就是性能要求越来越高。以互联网企业最常用的 MySQL 为例，再简单的查询，再高的硬件配置，单台 MySQL 机器支撑的 TPS 和 QPS 最高也就是万级，低的可能是几千，高的也不过几万。当用户量增长后，必然要考虑使用多台 MySQL，从一台 MySQL 到多台 MySQL 不是简单的数量的增加，而是本质上的改变，即原来集中式的存储变为了分布式的存储。
	  
	  
	  分布式将会带来复杂度的大幅度上升。以 MySQL 为例，分布式 MySQL 要考虑分库分表、读写分离、复制、同步等很多问题。
	  
	  
	- 可用性

	  用户量增大对技术带来的第二个挑战就是可用性要求越来越高。
	  
