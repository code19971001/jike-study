## 基础篇

#### 1.一条MySQL是如何执行的？

MySQL的逻辑架构图：

![img](https://blog-images-code1997.oss-cn-hangzhou.aliyuncs.com/java/project/gmall/02high/0d2070e8f84c4801adbfa03bda1f98d9.png)1）连接器

作用：我们会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。如果权限不足，则会返回：”Access denied for user“

```shell
mysql -h$ip -P$port -u$user -p
```

2）查询缓存

作用：之前执行过的语句以及结果会以key-value的形式，被直接缓存到内存中，key为查询语句，value为查询结果，如果我们的查询可以在缓存中找到，那么value就会直接返回给客户端。

建议：大多数形况下建议不要使用查询缓存。查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。

关闭查询缓存：query_cache_type=DEMAND

显示使用查询缓存：select SQL_CACHE * from T where ID=10；

**注意**：MySQL 8.0 版本直接将查询缓存的整块功能删掉了

3）分析器：要做什么

- 词法分析：识别出我们输入的SQL语句中的字符串代表什么。例如我们输入的select语句，那么他就是一个查询语句。
- 语法分析：按照语法规则，判断我们输入的MYSQL语句是否满足语法。如果语句不对则会返回”You have an error in your SQL syntax“，那么我们应该关注”user near“的内容。

4）优化器：怎么做

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。优化器阶段完成后，这个语句的执行方案就确定下来了。

5）执行器

作用：执行优化后的SQL语句，获取结果。

1. 判断一下你对这个表 T 有没有执行查询的权限，如果没有则返回权限不足。
2. 打开表，根据表的引擎定义，去使用引擎提供的接口：例如表ID字段没有索引，那么就会如下执行
   1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
   2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
   3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

慢查询日志中rows_examined 字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。



**问题**：如果我们查询了不存在的列，那么Unknown column ‘k’ in ‘where clause’”这个错误是在哪一个阶段爆出来？

分析器阶段抛出的错误，会检查表名，列名，函数签名等是否合法。

#### 2.一条更新语句的执行流程是什么？

和之前的查询过程基本一致，但是更新流程还涉及到了两个重要的日志模块：`redo log`（重做日志）和 `binlog`（归档日志）

1）redo log：是 InnoDB 引擎特有的日志

WAL(Write-Ahead logging)：关键点在于先写日志，再写磁盘。

具体来说：当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

如果更新的数据特别多怎么办呢？将一部分数据更新到磁盘中，然后清除这部分redo log，这样就有了一部分空间。

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示

![img](https://blog-images-code1997.oss-cn-hangzhou.aliyuncs.com/java/project/gmall/02high/16a7950217b3f0f4ed02db5db59562a7.png)

- write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。
- checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

- write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。

2）binlog日志：Server层的日志，也称为归档日志

binlog两种模式：一般采用row，但是日志会比较大。

- statement：记录sql语句。
- row：记录行的内容，更新以前以及更新以后。

为什么要有两份日志？

因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。

两者主要有三点不同：

- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

执行器和InnoDb引擎在执行update语句的时候的内部流程：

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

图解：浅色表示在InnoDb中执行；深色框表示在执行器中执行的。

![img](https://blog-images-code1997.oss-cn-hangzhou.aliyuncs.com/java/project/gmall/02high/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"。

两阶段提交：redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。

建议：

- redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。
- sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。

问题：

1）什么场景下一天一备比一周一备更具有优势？或者说它影响了数据库系统的哪个指标？

一天一备如果系统发生crash现象，那么恢复的时候就会快一些，备份库的数据更加接近crash时的状态，binlog日志相对更少，恢复起来比较快。但是频繁的全量备份需要消耗更多的存储空间。

#### 3.事务隔离

> mysql事务的支持是在引擎层实现的。

1）基本概念

当数据库上有多个事务同时执行的时候，就可能出现脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）的问题，为了解决这些问题，就有了“隔离级别”的概念。

在谈隔离级别之前，你首先要知道，你隔离得越严实，效率就会越低。因此很多时候，我们都要在二者之间寻找一个平衡点。SQL 标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。

- 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。
- 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。
- 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
- 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

![img](https://blog-images-code1997.oss-cn-hangzhou.aliyuncs.com/java/project/gmall/02high/7dea45932a6b722eb069d2264d0066f8.png)

我们来看看在不同的隔离级别下，事务 A 会有哪些不同的返回结果，也就是图里面 V1、V2、V3 的返回值分别是什么。

- 若隔离级别是“读未提交”， 则 V1 的值就是 2。这时候事务 B 虽然还没有提交，但是结果已经被 A 看到了。因此，V2、V3 也都是 2。
- 若隔离级别是“读提交”，则 V1 是 1，V2 的值是 2。事务 B 的更新在提交后才能被 A 看到。所以， V3 的值也是 2。
- 若隔离级别是“可重复读”，则 V1、V2 是 1，V3 是 2。之所以 V2 还是 1，遵循的就是这个要求：事务在执行期间看到的数据前后必须是一致的。
- 若隔离级别是“串行化”，则在事务 B 执行“将 1 改成 2”的时候，会被锁住。直到事务 A 提交后，事务 B 才可以继续执行。所以从 A 的角度看， V1、V2 值是 1，V3 的值是 2。

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。

- 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。
- 在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；
- 而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

Oracle 数据库的默认隔离级别其实就是“读提交”，因此如果数据库从oracle到mysql时要进行设置。

```sql
--查看事务隔离级别
show variables like 'transaction_isolation';
```

2）事务隔离的实现

> 以可重复读为例。

在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设将一个值1按照顺序改为2，3，4，那么在回滚日志里就会存在类似下面的记录。

![img](https://blog-images-code1997.oss-cn-hangzhou.aliyuncs.com/java/project/gmall/02high/d9c313809e5ac148fc39feff532f0fee.png)

当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。

什么时候删除回滚日志？系统会判断，当没有事务再需要用到这些回滚日志时，也就是当前系统里没有比这个回滚日志更早的read-view的时候，回滚日志会被删除。

注：在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。

建议：尽量不要使用长事务

- 会导致系统中存在很老的事务视图，在这个事务提交之前，回滚记录都需要保存，会占用大量的存储空间。
- 长事务还占用锁资源，也可能拖垮整个库

```sql
--查询长事务
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

问题：

你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？

